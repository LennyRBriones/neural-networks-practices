{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1XykZiNAw-Nhp5u2mHWK-cuHh9WRDZGVn",
      "authorship_tag": "ABX9TyO4O66iQcZD3v6MDtGb7AlA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LennyRBriones/neural-networks-practices/blob/main/Brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "Kd06-CcRnErO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ltJNbSWUlIoP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip =\"/content/drive/MyDrive/brain_class.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
        "zip_ref.extractall(\"content/drive/MyDrive/brain_class\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "IPAgEv9XmHAg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"content/drive/MyDrive/brain_class/Training\"\n",
        "test_dir = \"content/drive/MyDrive/brain_class/Testing\""
      ],
      "metadata": {
        "id": "1U8kcxQsmyWV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generators"
      ],
      "metadata": {
        "id": "mmzym1NEnDoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2) # splitting in 20% to validate performance"
      ],
      "metadata": {
        "id": "HWVjkcY7mp0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import test\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    subset =\"training\"\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHnJSOQ_nvwl",
        "outputId": "9bbdde08-e643-43ba-b231-3e67fc4e4764"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "Found 262 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]"
      ],
      "metadata": {
        "id": "dGhovmCAtQqa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbkCqZutzWD",
        "outputId": "b6defd44-51a5-4bb8-a959-ab11697fe4ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glioma', 'meningioma', 'notumor', 'pituitary']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotimages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize = (15,15))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img[:,:,0])\n",
        "    ax.axis(\"off\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "H-fTNXXDt0Pf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_training_images, _ = next(train_generator)\n",
        "plotimages(sample_training_images[5:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "KHklUF-guQbp",
        "outputId": "00ac212c-eb3d-4eb0-c0e7-844982ef159b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Tuner"
      ],
      "metadata": {
        "id": "mrjnb3hwzxRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "Jx4TqY0T05LX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBnvREUMuc-b",
        "outputId": "ed1d7679-450b-4f73-9c5f-2407c50f187f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_constructor(hp):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(20, (3,3), activation =\"relu\", input_shape = (32,32, 1)))\n",
        "  model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  #Dynamic generator of neurons\n",
        "  hp_units = hp.Int(\"units\", min_value = 10, max_value = 80, step = 10)\n",
        "  model.add(tf.keras.layers.Dense(units = hp_units, activation = \"relu\", kernel_regularizer = regularizers.l2(1e-5)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(10, activation = \"relu\", kernel_regularizer= regularizers.l2(1e-5)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(len(classes), activation = \"softmax\" ))\n",
        "\n",
        "  hp_learning_rate = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate= hp_learning_rate), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "69jIj4AX0BH6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    model_constructor,\n",
        "    objective = \"val_accuracy\", #to see generalization in new data\n",
        "    max_epochs=12,\n",
        "    factor = 3,\n",
        "    directory = \"models/\",\n",
        "    project_name = \"brain-lenn-tunner\"\n",
        ")"
      ],
      "metadata": {
        "id": "dIieFIdp0-mj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_generator, epochs = 12, validation_data = validation_generator)\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "                                          #trials help us to re-test the result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfwnDFlx1QMh",
        "outputId": "3035ac40-88d9-41c0-990c-b8772cde90e4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 07m 35s]\n",
            "val_accuracy: 0.3091602921485901\n",
            "\n",
            "Best val_accuracy So Far: 0.9351145029067993\n",
            "Total elapsed time: 01h 20m 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get(\"units\")) #to get the best configuration of neurons"
      ],
      "metadata": {
        "id": "6atExCmO1c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "182585ba-4cee-44e6-c090-3e56927afb9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get(\"learning_rate\")) #to get the best configuration of learning rate"
      ],
      "metadata": {
        "id": "YdKFIJly1g3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b91058d9-fe53-4a59-8187-bda6cad905c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback_early = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 3, mode = \"auto\") #it could be min or max depends of the metric"
      ],
      "metadata": {
        "id": "pdaLSa9HaScM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history_hypermodel = hypermodel.fit(\n",
        "    train_generator,\n",
        "    epochs = 12,\n",
        "    callbacks = [callback_early],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "id": "cleAzn-nuOqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c43b69-fec9-4f58-a646-77319b6353c3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "476/476 [==============================] - 39s 79ms/step - loss: 0.9931 - accuracy: 0.5611 - val_loss: 1.0747 - val_accuracy: 0.5840\n",
            "Epoch 2/12\n",
            "476/476 [==============================] - 25s 52ms/step - loss: 0.6713 - accuracy: 0.7344 - val_loss: 0.8764 - val_accuracy: 0.6679\n",
            "Epoch 3/12\n",
            "476/476 [==============================] - 21s 45ms/step - loss: 0.5954 - accuracy: 0.7586 - val_loss: 0.9035 - val_accuracy: 0.6450\n",
            "Epoch 4/12\n",
            "476/476 [==============================] - 24s 51ms/step - loss: 0.5255 - accuracy: 0.8051 - val_loss: 0.6498 - val_accuracy: 0.7176\n",
            "Epoch 5/12\n",
            "476/476 [==============================] - 22s 45ms/step - loss: 0.4561 - accuracy: 0.8316 - val_loss: 0.5730 - val_accuracy: 0.7557\n",
            "Epoch 6/12\n",
            "476/476 [==============================] - 23s 48ms/step - loss: 0.4231 - accuracy: 0.8465 - val_loss: 0.5589 - val_accuracy: 0.7748\n",
            "Epoch 7/12\n",
            "476/476 [==============================] - 22s 47ms/step - loss: 0.3865 - accuracy: 0.8568 - val_loss: 0.6348 - val_accuracy: 0.7405\n",
            "Epoch 8/12\n",
            "476/476 [==============================] - 23s 48ms/step - loss: 0.3520 - accuracy: 0.8750 - val_loss: 0.5884 - val_accuracy: 0.7214\n",
            "Epoch 9/12\n",
            "476/476 [==============================] - 24s 50ms/step - loss: 0.3342 - accuracy: 0.8796 - val_loss: 0.4213 - val_accuracy: 0.8244\n",
            "Epoch 10/12\n",
            "476/476 [==============================] - 24s 51ms/step - loss: 0.3076 - accuracy: 0.8867 - val_loss: 0.4370 - val_accuracy: 0.8206\n",
            "Epoch 11/12\n",
            "476/476 [==============================] - 24s 51ms/step - loss: 0.2863 - accuracy: 0.9004 - val_loss: 0.3605 - val_accuracy: 0.8626\n",
            "Epoch 12/12\n",
            "476/476 [==============================] - 25s 52ms/step - loss: 0.2592 - accuracy: 0.9091 - val_loss: 0.3672 - val_accuracy: 0.8817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the config of the model\n",
        "config_dict = hypermodel.get_config()"
      ],
      "metadata": {
        "id": "u1cHtNYEmsFm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyVG0tMomvvr",
        "outputId": "9f5ccc64-0222-4024-8fb0-f09a00f60d22"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 32, 32, 1), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'conv2d_1_input'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 32, 32, 1), 'filters': 20, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 40, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 9.999999747378752e-06}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 9.999999747378752e-06}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_same_config = tf.keras.Sequential.from_config(config_dict)"
      ],
      "metadata": {
        "id": "VPBcoJTOm0yl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_same_config.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2UzQVFDm7iQ",
        "outputId": "c2c19221-ada6-4b9e-fe04-b04d9575800e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 40)                180040    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                410       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,694\n",
            "Trainable params: 180,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "aPurqU3knER5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "   model = tf.keras.models.Sequential([\n",
        "             tf.keras.layers.Conv2D(20, (3,3), activation = \"relu\", input_shape = (32, 32,1)),\n",
        "             tf.keras.layers.MaxPool2D((2,2)),\n",
        "             tf.keras.layers.Flatten(),\n",
        "             tf.keras.layers.Dense(40, kernel_regularizer= regularizers.l2(0.001), activation = \"relu\"),\n",
        "             tf.keras.layers.Dropout(0.2),\n",
        "             tf.keras.layers.Dense(10, kernel_regularizer= regularizers.l2(0.001), activation = \"relu\"),\n",
        "             tf.keras.layers.Dropout(0.2),\n",
        "             tf.keras.layers.Dense(len(classes), activation =\"softmax\")\n",
        "   ])\n",
        "   return model\n",
        "\n",
        "model_early =  get_model()\n",
        "model_early.summary()\n",
        "\n",
        "model_early.compile(optimizer= \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm18KpSrc4Ev",
        "outputId": "62116486-84f3-4b56-e6c1-8a14f23b8277"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 40)                180040    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                410       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,694\n",
            "Trainable params: 180,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight = get_model()\n",
        "model_weight.summary()"
      ],
      "metadata": {
        "id": "cU8GeIW3nIiD",
        "outputId": "13bba8cb-869e-442a-a610-60d0374a3111",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 40)                180040    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                410       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,694\n",
            "Trainable params: 180,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "EHpxUan8fHEK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"model_checkpoints/checkpoint\"\n",
        "checkpoint_weights = ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    frecuency = \"epoch\",\n",
        "    save_weights_only = True,\n",
        "    verbose = 1 #show us information during training\n",
        ")"
      ],
      "metadata": {
        "id": "wRqw04lvfJJW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_weigth = model_weight.fit(\n",
        "    train_generator,\n",
        "    epochs = 20,\n",
        "    callbacks = [checkpoint_weights],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjsKOB9cfM1W",
        "outputId": "0fe486bf-9f23-4912-b5af-f16d2e67e1dd"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4131 - accuracy: 0.8948\n",
            "Epoch 1: val_accuracy did not improve from 0.88550\n",
            "476/476 [==============================] - 30s 63ms/step - loss: 0.4131 - accuracy: 0.8948 - val_loss: 0.5106 - val_accuracy: 0.8626\n",
            "Epoch 2/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3997 - accuracy: 0.8984\n",
            "Epoch 2: val_accuracy improved from 0.88550 to 0.88931, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 52ms/step - loss: 0.3993 - accuracy: 0.8986 - val_loss: 0.4696 - val_accuracy: 0.8893\n",
            "Epoch 3/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3959 - accuracy: 0.9035\n",
            "Epoch 3: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 27s 57ms/step - loss: 0.3959 - accuracy: 0.9035 - val_loss: 0.4477 - val_accuracy: 0.8626\n",
            "Epoch 4/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3669 - accuracy: 0.9111\n",
            "Epoch 4: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3667 - accuracy: 0.9111 - val_loss: 0.4514 - val_accuracy: 0.8855\n",
            "Epoch 5/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9111\n",
            "Epoch 5: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3710 - accuracy: 0.9111 - val_loss: 0.4477 - val_accuracy: 0.8817\n",
            "Epoch 6/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3757 - accuracy: 0.9119\n",
            "Epoch 6: val_accuracy improved from 0.88931 to 0.89313, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 26s 55ms/step - loss: 0.3757 - accuracy: 0.9119 - val_loss: 0.4569 - val_accuracy: 0.8931\n",
            "Epoch 7/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3710 - accuracy: 0.9107\n",
            "Epoch 7: val_accuracy improved from 0.89313 to 0.92748, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 22s 47ms/step - loss: 0.3710 - accuracy: 0.9107 - val_loss: 0.3592 - val_accuracy: 0.9275\n",
            "Epoch 8/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3564 - accuracy: 0.9207\n",
            "Epoch 8: val_accuracy improved from 0.92748 to 0.93893, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 53ms/step - loss: 0.3568 - accuracy: 0.9207 - val_loss: 0.3489 - val_accuracy: 0.9389\n",
            "Epoch 9/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3474 - accuracy: 0.9219\n",
            "Epoch 9: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.3474 - accuracy: 0.9219 - val_loss: 0.5379 - val_accuracy: 0.8511\n",
            "Epoch 10/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3377 - accuracy: 0.9261\n",
            "Epoch 10: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3377 - accuracy: 0.9261 - val_loss: 0.3427 - val_accuracy: 0.9237\n",
            "Epoch 11/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3532 - accuracy: 0.9207\n",
            "Epoch 11: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3532 - accuracy: 0.9207 - val_loss: 0.4172 - val_accuracy: 0.9046\n",
            "Epoch 12/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.9286\n",
            "Epoch 12: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 24s 50ms/step - loss: 0.3395 - accuracy: 0.9286 - val_loss: 0.4373 - val_accuracy: 0.8855\n",
            "Epoch 13/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3273 - accuracy: 0.9300\n",
            "Epoch 13: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 23s 48ms/step - loss: 0.3273 - accuracy: 0.9300 - val_loss: 0.4179 - val_accuracy: 0.9198\n",
            "Epoch 14/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3102 - accuracy: 0.9361\n",
            "Epoch 14: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 24s 50ms/step - loss: 0.3108 - accuracy: 0.9359 - val_loss: 0.4464 - val_accuracy: 0.9084\n",
            "Epoch 15/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3395 - accuracy: 0.9282\n",
            "Epoch 15: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3395 - accuracy: 0.9282 - val_loss: 0.4710 - val_accuracy: 0.9084\n",
            "Epoch 16/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3183 - accuracy: 0.9371\n",
            "Epoch 16: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3183 - accuracy: 0.9371 - val_loss: 0.3743 - val_accuracy: 0.9160\n",
            "Epoch 17/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3135 - accuracy: 0.9308\n",
            "Epoch 17: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3135 - accuracy: 0.9308 - val_loss: 0.3652 - val_accuracy: 0.9389\n",
            "Epoch 18/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3169 - accuracy: 0.9347\n",
            "Epoch 18: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.3169 - accuracy: 0.9347 - val_loss: 0.4523 - val_accuracy: 0.8969\n",
            "Epoch 19/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3193 - accuracy: 0.9325\n",
            "Epoch 19: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 21s 45ms/step - loss: 0.3191 - accuracy: 0.9326 - val_loss: 0.3903 - val_accuracy: 0.9275\n",
            "Epoch 20/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.2861 - accuracy: 0.9450\n",
            "Epoch 20: val_accuracy did not improve from 0.93893\n",
            "476/476 [==============================] - 24s 50ms/step - loss: 0.2861 - accuracy: 0.9450 - val_loss: 0.4123 - val_accuracy: 0.9046\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Model Weigths"
      ],
      "metadata": {
        "id": "3dyGzYL6fVok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"model_checkpoints_complete\" #because we want to save all\n",
        "checkpoint_weights = ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    frecuency = \"epoch\",\n",
        "    save_weights_only = False, #this because we want to save model and wights\n",
        "    monitor = \"val_accuracy\", #to save only the best model\n",
        "    save_best_only = True,\n",
        "    verbose = 1 #show us information during training\n",
        ")"
      ],
      "metadata": {
        "id": "2OV3sGoof0n0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete = get_model()\n",
        "model_complete.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "history_complete = model_complete.fit(\n",
        "    train_generator,\n",
        "    epochs = 20,\n",
        "    callbacks = [checkpoint_weights],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE3R7c0cf6b0",
        "outputId": "51dc5d58-7659-4603-d239-d313336d4de0"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.9547 - accuracy: 0.6153\n",
            "Epoch 1: val_accuracy improved from -inf to 0.66412, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 50ms/step - loss: 0.9541 - accuracy: 0.6155 - val_loss: 0.8754 - val_accuracy: 0.6641\n",
            "Epoch 2/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.7040 - accuracy: 0.7546\n",
            "Epoch 2: val_accuracy improved from 0.66412 to 0.72137, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 23s 48ms/step - loss: 0.7035 - accuracy: 0.7546 - val_loss: 0.8073 - val_accuracy: 0.7214\n",
            "Epoch 3/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.6120 - accuracy: 0.7968\n",
            "Epoch 3: val_accuracy improved from 0.72137 to 0.72901, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 24s 51ms/step - loss: 0.6124 - accuracy: 0.7966 - val_loss: 0.7054 - val_accuracy: 0.7290\n",
            "Epoch 4/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.5671 - accuracy: 0.8260\n",
            "Epoch 4: val_accuracy improved from 0.72901 to 0.80534, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 24s 50ms/step - loss: 0.5671 - accuracy: 0.8260 - val_loss: 0.6160 - val_accuracy: 0.8053\n",
            "Epoch 5/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.5265 - accuracy: 0.8416\n",
            "Epoch 5: val_accuracy did not improve from 0.80534\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.5259 - accuracy: 0.8419 - val_loss: 0.6470 - val_accuracy: 0.7710\n",
            "Epoch 6/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.5087 - accuracy: 0.8547\n",
            "Epoch 6: val_accuracy did not improve from 0.80534\n",
            "476/476 [==============================] - 22s 45ms/step - loss: 0.5087 - accuracy: 0.8547 - val_loss: 0.5573 - val_accuracy: 0.7786\n",
            "Epoch 7/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4967 - accuracy: 0.8614\n",
            "Epoch 7: val_accuracy did not improve from 0.80534\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.4967 - accuracy: 0.8615 - val_loss: 0.6198 - val_accuracy: 0.7786\n",
            "Epoch 8/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4702 - accuracy: 0.8715\n",
            "Epoch 8: val_accuracy improved from 0.80534 to 0.83588, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 52ms/step - loss: 0.4702 - accuracy: 0.8715 - val_loss: 0.4995 - val_accuracy: 0.8359\n",
            "Epoch 9/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4364 - accuracy: 0.8836\n",
            "Epoch 9: val_accuracy did not improve from 0.83588\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.4364 - accuracy: 0.8836 - val_loss: 0.5459 - val_accuracy: 0.8015\n",
            "Epoch 10/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4319 - accuracy: 0.8850\n",
            "Epoch 10: val_accuracy improved from 0.83588 to 0.84351, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 52ms/step - loss: 0.4319 - accuracy: 0.8850 - val_loss: 0.5735 - val_accuracy: 0.8435\n",
            "Epoch 11/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4312 - accuracy: 0.8857\n",
            "Epoch 11: val_accuracy did not improve from 0.84351\n",
            "476/476 [==============================] - 22s 46ms/step - loss: 0.4312 - accuracy: 0.8857 - val_loss: 0.4963 - val_accuracy: 0.8130\n",
            "Epoch 12/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4041 - accuracy: 0.8992\n",
            "Epoch 12: val_accuracy did not improve from 0.84351\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.4041 - accuracy: 0.8992 - val_loss: 0.5507 - val_accuracy: 0.8130\n",
            "Epoch 13/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3898 - accuracy: 0.9107\n",
            "Epoch 13: val_accuracy improved from 0.84351 to 0.85115, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 24s 51ms/step - loss: 0.3898 - accuracy: 0.9107 - val_loss: 0.4501 - val_accuracy: 0.8511\n",
            "Epoch 14/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3823 - accuracy: 0.9095\n",
            "Epoch 14: val_accuracy improved from 0.85115 to 0.85878, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 23s 49ms/step - loss: 0.3829 - accuracy: 0.9091 - val_loss: 0.4732 - val_accuracy: 0.8588\n",
            "Epoch 15/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3890 - accuracy: 0.9061\n",
            "Epoch 15: val_accuracy did not improve from 0.85878\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.3886 - accuracy: 0.9063 - val_loss: 0.4576 - val_accuracy: 0.8588\n",
            "Epoch 16/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3807 - accuracy: 0.9146\n",
            "Epoch 16: val_accuracy improved from 0.85878 to 0.88550, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 53ms/step - loss: 0.3807 - accuracy: 0.9146 - val_loss: 0.4318 - val_accuracy: 0.8855\n",
            "Epoch 17/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3607 - accuracy: 0.9184\n",
            "Epoch 17: val_accuracy improved from 0.88550 to 0.90840, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 23s 49ms/step - loss: 0.3612 - accuracy: 0.9182 - val_loss: 0.3955 - val_accuracy: 0.9084\n",
            "Epoch 18/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3645 - accuracy: 0.9184\n",
            "Epoch 18: val_accuracy did not improve from 0.90840\n",
            "476/476 [==============================] - 23s 48ms/step - loss: 0.3645 - accuracy: 0.9184 - val_loss: 0.4622 - val_accuracy: 0.8664\n",
            "Epoch 19/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3458 - accuracy: 0.9233\n",
            "Epoch 19: val_accuracy did not improve from 0.90840\n",
            "476/476 [==============================] - 23s 49ms/step - loss: 0.3459 - accuracy: 0.9233 - val_loss: 0.4176 - val_accuracy: 0.8969\n",
            "Epoch 20/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3506 - accuracy: 0.9251\n",
            "Epoch 20: val_accuracy improved from 0.90840 to 0.92366, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 25s 52ms/step - loss: 0.3509 - accuracy: 0.9251 - val_loss: 0.3765 - val_accuracy: 0.9237\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving in a ZIP"
      ],
      "metadata": {
        "id": "OOvx1Esdf9p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip model_checkpoints_complete *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07k3X_epf_4u",
        "outputId": "7a48edf3-c7c5-4dcf-d617-3e6d8d83be90"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "updating: content/ (stored 0%)\n",
            "updating: drive/ (stored 0%)\n",
            "updating: model_checkpoints/ (stored 0%)\n",
            "updating: model_checkpoints_complete/ (stored 0%)\n",
            "updating: models/ (stored 0%)\n",
            "updating: sample_data/ (stored 0%)\n",
            "  adding: brain_model.h5 (deflated 9%)\n",
            "  adding: save_model_complete/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving in H5py"
      ],
      "metadata": {
        "id": "TsMRa4Z2gRvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQpEzXk7gBxs",
        "outputId": "48cd778b-70df-4132-93ab-5ab66271d5dc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "NQGHbjAigX7n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete.save(\"save_model_complete/mymodel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7EyHfCo4Ovv",
        "outputId": "8f688757-be4b-41d4-95d5-4d0a900604bc"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _update_step_xla while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew = tf.keras.models.load_model(\"save_model_complete/mymodel\") "
      ],
      "metadata": {
        "id": "KUAOCa_R4Qa0"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftDQPwe24SsC",
        "outputId": "f9f39b8d-e44a-4481-dea0-f8bba5b56c36"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 4s 38ms/step - loss: 0.4182 - accuracy: 0.8947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.41820916533470154, 0.8947368264198303]"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTnjMWpG4UoL",
        "outputId": "011f4e04-b075-49d2-d15d-28fc0af80120"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 3s 30ms/step - loss: 0.4182 - accuracy: 0.8947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4182092249393463, 0.8947368264198303]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew.save(\"brain_model.h5\")"
      ],
      "metadata": {
        "id": "wiqYn7p_5xeU"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew2 = tf.keras.models.load_model(\"brain_model.h5\")"
      ],
      "metadata": {
        "id": "8w_JgIEfgamx"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew2.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyGjhRfJgd6k",
        "outputId": "0c26b1f8-a24f-41fc-9514-60b59bd53f5d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 3s 30ms/step - loss: 0.4182 - accuracy: 0.8947\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4182092249393463, 0.8947368264198303]"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    }
  ]
}