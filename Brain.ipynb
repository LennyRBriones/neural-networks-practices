{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "https://github.com/LennyRBriones/neural-networks-practices/blob/main/Brain.ipynb",
      "authorship_tag": "ABX9TyPN78ywycHyZTt4hve4KvuX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LennyRBriones/neural-networks-practices/blob/main/Brain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Libraries"
      ],
      "metadata": {
        "id": "Kd06-CcRnErO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ltJNbSWUlIoP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip =\"/content/drive/MyDrive/brain_class.zip\"\n",
        "zip_ref = zipfile.ZipFile(local_zip,\"r\")\n",
        "zip_ref.extractall(\"content/drive/MyDrive/brain_class\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import string\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "IPAgEv9XmHAg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"content/drive/MyDrive/brain_class/Training\"\n",
        "test_dir = \"content/drive/MyDrive/brain_class/Testing\""
      ],
      "metadata": {
        "id": "1U8kcxQsmyWV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Generators"
      ],
      "metadata": {
        "id": "mmzym1NEnDoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1/255)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255, validation_split = 0.2) # splitting in 20% to validate performance"
      ],
      "metadata": {
        "id": "HWVjkcY7mp0i"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python import test\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    subset =\"training\"\n",
        ")\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        "    subset = \"validation\"\n",
        ")\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size = (32, 32),\n",
        "    batch_size = 12,\n",
        "    class_mode = \"categorical\",\n",
        "    color_mode = \"grayscale\",\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHnJSOQ_nvwl",
        "outputId": "a647b454-c063-4d7b-d8a0-efe2bb76061b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 5712 images belonging to 4 classes.\n",
            "Found 262 images belonging to 4 classes.\n",
            "Found 1311 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"glioma\", \"meningioma\", \"notumor\", \"pituitary\"]"
      ],
      "metadata": {
        "id": "dGhovmCAtQqa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EhbkCqZutzWD",
        "outputId": "41c4b242-9c96-4668-9d77-2c3563e54830"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glioma', 'meningioma', 'notumor', 'pituitary']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plotimages(images_arr):\n",
        "  fig, axes = plt.subplots(1, 5, figsize = (15,15))\n",
        "  axes = axes.flatten()\n",
        "  for img, ax in zip(images_arr, axes):\n",
        "    ax.imshow(img[:,:,0])\n",
        "    ax.axis(\"off\")\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "H-fTNXXDt0Pf"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_training_images, _ = next(train_generator)\n",
        "plotimages(sample_training_images[5:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "KHklUF-guQbp",
        "outputId": "c5438d28-2c30-4920-816e-d0d91b1b5c08"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 5 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Keras Tuner"
      ],
      "metadata": {
        "id": "mrjnb3hwzxRe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import regularizers"
      ],
      "metadata": {
        "id": "Jx4TqY0T05LX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q -U keras-tuner\n",
        "import keras_tuner as kt\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBnvREUMuc-b",
        "outputId": "ec1b6317-df0a-4edf-8c0b-f1b49069cc49"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/176.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.1/176.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def model_constructor(hp):\n",
        "  model = tf.keras.models.Sequential()\n",
        "  model.add(tf.keras.layers.Conv2D(20, (3,3), activation =\"relu\", input_shape = (32,32, 1)))\n",
        "  model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
        "  model.add(tf.keras.layers.Flatten())\n",
        "\n",
        "  #Dynamic generator of neurons\n",
        "  hp_units = hp.Int(\"units\", min_value = 10, max_value = 80, step = 10)\n",
        "  model.add(tf.keras.layers.Dense(units = hp_units, activation = \"relu\", kernel_regularizer = regularizers.l2(1e-5)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(10, activation = \"relu\", kernel_regularizer= regularizers.l2(1e-5)))\n",
        "  model.add(tf.keras.layers.Dropout(0.2))\n",
        "  model.add(tf.keras.layers.Dense(len(classes), activation = \"softmax\" ))\n",
        "\n",
        "  hp_learning_rate = hp.Choice(\"learning_rate\", values = [1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer = keras.optimizers.Adam(learning_rate= hp_learning_rate), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "69jIj4AX0BH6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner = kt.Hyperband(\n",
        "    model_constructor,\n",
        "    objective = \"val_accuracy\", #to see generalization in new data\n",
        "    max_epochs=12,\n",
        "    factor = 3,\n",
        "    directory = \"models/\",\n",
        "    project_name = \"brain-lenn-tunner\"\n",
        ")"
      ],
      "metadata": {
        "id": "dIieFIdp0-mj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(train_generator, epochs = 12, validation_data = validation_generator)\n",
        "\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials = 1)[0]\n",
        "                                          #trials help us to re-test the result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfwnDFlx1QMh",
        "outputId": "5173f330-28f8-4dd6-f5a5-311c1a7fe3c2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 03m 52s]\n",
            "val_accuracy: 0.7290076613426208\n",
            "\n",
            "Best val_accuracy So Far: 0.919847309589386\n",
            "Total elapsed time: 00h 44m 15s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get(\"units\")) #to get the best configuration of neurons"
      ],
      "metadata": {
        "id": "6atExCmO1c43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "055cf8e4-8eea-450d-c48b-ae1105f6ecff"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "70\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(best_hps.get(\"learning_rate\")) #to get the best configuration of learning rate"
      ],
      "metadata": {
        "id": "YdKFIJly1g3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec022a3-a686-49d8-9b5c-f5af6b9daa5a"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callback_early = tf.keras.callbacks.EarlyStopping(monitor = \"loss\", patience = 3, mode = \"auto\") #it could be min or max depends of the metric"
      ],
      "metadata": {
        "id": "pdaLSa9HaScM"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hypermodel = tuner.hypermodel.build(best_hps)\n",
        "\n",
        "history_hypermodel = hypermodel.fit(\n",
        "    train_generator,\n",
        "    epochs = 12,\n",
        "    callbacks = [callback_early],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "id": "cleAzn-nuOqx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa4ea488-64d6-4b7d-e569-e152a7e58fb9"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "476/476 [==============================] - 19s 36ms/step - loss: 0.8998 - accuracy: 0.6131 - val_loss: 0.8801 - val_accuracy: 0.6679\n",
            "Epoch 2/12\n",
            "476/476 [==============================] - 19s 39ms/step - loss: 0.5691 - accuracy: 0.7798 - val_loss: 0.6755 - val_accuracy: 0.6794\n",
            "Epoch 3/12\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.4587 - accuracy: 0.8300 - val_loss: 0.6305 - val_accuracy: 0.6947\n",
            "Epoch 4/12\n",
            "476/476 [==============================] - 17s 37ms/step - loss: 0.3888 - accuracy: 0.8517 - val_loss: 0.5082 - val_accuracy: 0.7786\n",
            "Epoch 5/12\n",
            "476/476 [==============================] - 18s 38ms/step - loss: 0.3475 - accuracy: 0.8683 - val_loss: 0.4343 - val_accuracy: 0.8244\n",
            "Epoch 6/12\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.3081 - accuracy: 0.8836 - val_loss: 0.5035 - val_accuracy: 0.8053\n",
            "Epoch 7/12\n",
            "476/476 [==============================] - 18s 38ms/step - loss: 0.2741 - accuracy: 0.9025 - val_loss: 0.4004 - val_accuracy: 0.8664\n",
            "Epoch 8/12\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.2328 - accuracy: 0.9207 - val_loss: 0.3088 - val_accuracy: 0.9008\n",
            "Epoch 9/12\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.2055 - accuracy: 0.9347 - val_loss: 0.3215 - val_accuracy: 0.9008\n",
            "Epoch 10/12\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.1912 - accuracy: 0.9364 - val_loss: 0.3231 - val_accuracy: 0.8931\n",
            "Epoch 11/12\n",
            "476/476 [==============================] - 17s 37ms/step - loss: 0.1754 - accuracy: 0.9412 - val_loss: 0.2552 - val_accuracy: 0.9198\n",
            "Epoch 12/12\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.1672 - accuracy: 0.9452 - val_loss: 0.2958 - val_accuracy: 0.8969\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to save the config of the model\n",
        "config_dict = hypermodel.get_config()"
      ],
      "metadata": {
        "id": "u1cHtNYEmsFm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(config_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyVG0tMomvvr",
        "outputId": "6a6d3eaf-3d85-4eb1-ba21-c5987e37ea1d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'sequential_1', 'layers': [{'class_name': 'InputLayer', 'config': {'batch_input_shape': (None, 32, 32, 1), 'dtype': 'float32', 'sparse': False, 'ragged': False, 'name': 'conv2d_1_input'}}, {'class_name': 'Conv2D', 'config': {'name': 'conv2d_1', 'trainable': True, 'dtype': 'float32', 'batch_input_shape': (None, 32, 32, 1), 'filters': 20, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'groups': 1, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'MaxPooling2D', 'config': {'name': 'max_pooling2d_1', 'trainable': True, 'dtype': 'float32', 'pool_size': (2, 2), 'padding': 'valid', 'strides': (2, 2), 'data_format': 'channels_last'}}, {'class_name': 'Flatten', 'config': {'name': 'flatten_1', 'trainable': True, 'dtype': 'float32', 'data_format': 'channels_last'}}, {'class_name': 'Dense', 'config': {'name': 'dense_3', 'trainable': True, 'dtype': 'float32', 'units': 70, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 9.999999747378752e-06}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_2', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_4', 'trainable': True, 'dtype': 'float32', 'units': 10, 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': {'class_name': 'L2', 'config': {'l2': 9.999999747378752e-06}}, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}, {'class_name': 'Dropout', 'config': {'name': 'dropout_3', 'trainable': True, 'dtype': 'float32', 'rate': 0.2, 'noise_shape': None, 'seed': None}}, {'class_name': 'Dense', 'config': {'name': 'dense_5', 'trainable': True, 'dtype': 'float32', 'units': 4, 'activation': 'softmax', 'use_bias': True, 'kernel_initializer': {'class_name': 'GlorotUniform', 'config': {'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_same_config = tf.keras.Sequential.from_config(config_dict)"
      ],
      "metadata": {
        "id": "VPBcoJTOm0yl"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_same_config.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2UzQVFDm7iQ",
        "outputId": "162d3aa2-7960-4b85-c54b-1f20781ab585"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 70)                315070    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 70)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 10)                710       \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 316,024\n",
            "Trainable params: 316,024\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "aPurqU3knER5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "   model = tf.keras.models.Sequential([\n",
        "             tf.keras.layers.Conv2D(20, (3,3), activation = \"relu\", input_shape = (32, 32,1)),\n",
        "             tf.keras.layers.MaxPool2D((2,2)),\n",
        "             tf.keras.layers.Flatten(),\n",
        "             tf.keras.layers.Dense(40, kernel_regularizer= regularizers.l2(0.001), activation = \"relu\"),\n",
        "             tf.keras.layers.Dropout(0.2),\n",
        "             tf.keras.layers.Dense(10, kernel_regularizer= regularizers.l2(0.001), activation = \"relu\"),\n",
        "             tf.keras.layers.Dropout(0.2),\n",
        "             tf.keras.layers.Dense(len(classes), activation =\"softmax\")\n",
        "   ])\n",
        "   return model\n",
        "\n",
        "model_early =  get_model()\n",
        "model_early.summary()\n",
        "\n",
        "model_early.compile(optimizer= \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rm18KpSrc4Ev",
        "outputId": "08bac0c1-df4a-40cc-d970-9ced52731c09"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_2 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 40)                180040    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 10)                410       \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,694\n",
            "Trainable params: 180,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight = get_model()\n",
        "model_weight.summary()"
      ],
      "metadata": {
        "id": "cU8GeIW3nIiD",
        "outputId": "5ea2995f-4dc4-4d73-8498-2efffcd0e2a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 30, 30, 20)        200       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 15, 15, 20)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_3 (Flatten)         (None, 4500)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 40)                180040    \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 40)                0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 10)                410       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 10)                0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 44        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,694\n",
            "Trainable params: 180,694\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_weight.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
      ],
      "metadata": {
        "id": "EHpxUan8fHEK"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"model_checkpoints/checkpoint\"\n",
        "checkpoint_weights = ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    frecuency = \"epoch\",\n",
        "    save_weights_only = True,\n",
        "    verbose = 1 #show us information during training\n",
        ")"
      ],
      "metadata": {
        "id": "wRqw04lvfJJW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history_weigth = model_weight.fit(\n",
        "    train_generator,\n",
        "    epochs = 20,\n",
        "    callbacks = [checkpoint_weights],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjsKOB9cfM1W",
        "outputId": "6df547c5-c002-4141-9d60-8aa9f835840a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.9999 - accuracy: 0.5858\n",
            "Epoch 1: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 21s 39ms/step - loss: 0.9999 - accuracy: 0.5858 - val_loss: 1.1468 - val_accuracy: 0.6679\n",
            "Epoch 2/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.7157 - accuracy: 0.7461\n",
            "Epoch 2: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.7157 - accuracy: 0.7461 - val_loss: 0.8379 - val_accuracy: 0.6908\n",
            "Epoch 3/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.6341 - accuracy: 0.7804\n",
            "Epoch 3: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 38ms/step - loss: 0.6342 - accuracy: 0.7803 - val_loss: 0.7421 - val_accuracy: 0.7023\n",
            "Epoch 4/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.5857 - accuracy: 0.7924\n",
            "Epoch 4: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.5857 - accuracy: 0.7924 - val_loss: 0.6552 - val_accuracy: 0.7672\n",
            "Epoch 5/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.5694 - accuracy: 0.8118\n",
            "Epoch 5: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.5696 - accuracy: 0.8116 - val_loss: 0.6814 - val_accuracy: 0.7405\n",
            "Epoch 6/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.5216 - accuracy: 0.8400\n",
            "Epoch 6: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 38ms/step - loss: 0.5213 - accuracy: 0.8400 - val_loss: 0.5823 - val_accuracy: 0.7939\n",
            "Epoch 7/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.5093 - accuracy: 0.8463\n",
            "Epoch 7: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 19s 39ms/step - loss: 0.5092 - accuracy: 0.8463 - val_loss: 0.8326 - val_accuracy: 0.6947\n",
            "Epoch 8/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4907 - accuracy: 0.8565\n",
            "Epoch 8: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 37ms/step - loss: 0.4912 - accuracy: 0.8563 - val_loss: 0.6635 - val_accuracy: 0.7786\n",
            "Epoch 9/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4710 - accuracy: 0.8633\n",
            "Epoch 9: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.4710 - accuracy: 0.8633 - val_loss: 0.6189 - val_accuracy: 0.7710\n",
            "Epoch 10/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4497 - accuracy: 0.8752\n",
            "Epoch 10: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 19s 40ms/step - loss: 0.4497 - accuracy: 0.8752 - val_loss: 0.5849 - val_accuracy: 0.8015\n",
            "Epoch 11/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4300 - accuracy: 0.8822\n",
            "Epoch 11: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.4300 - accuracy: 0.8822 - val_loss: 0.5360 - val_accuracy: 0.8092\n",
            "Epoch 12/20\n",
            "474/476 [============================>.] - ETA: 0s - loss: 0.4277 - accuracy: 0.8833\n",
            "Epoch 12: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.4270 - accuracy: 0.8838 - val_loss: 0.5124 - val_accuracy: 0.8664\n",
            "Epoch 13/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4113 - accuracy: 0.8925\n",
            "Epoch 13: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 19s 40ms/step - loss: 0.4113 - accuracy: 0.8925 - val_loss: 0.5073 - val_accuracy: 0.8550\n",
            "Epoch 14/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4126 - accuracy: 0.8946\n",
            "Epoch 14: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.4126 - accuracy: 0.8946 - val_loss: 0.4601 - val_accuracy: 0.8740\n",
            "Epoch 15/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3904 - accuracy: 0.9025\n",
            "Epoch 15: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 38ms/step - loss: 0.3903 - accuracy: 0.9025 - val_loss: 0.5090 - val_accuracy: 0.8511\n",
            "Epoch 16/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3920 - accuracy: 0.9044\n",
            "Epoch 16: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.3917 - accuracy: 0.9046 - val_loss: 0.4325 - val_accuracy: 0.9046\n",
            "Epoch 17/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3795 - accuracy: 0.9068\n",
            "Epoch 17: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.3793 - accuracy: 0.9070 - val_loss: 0.4454 - val_accuracy: 0.9160\n",
            "Epoch 18/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3733 - accuracy: 0.9079\n",
            "Epoch 18: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.3733 - accuracy: 0.9079 - val_loss: 0.4281 - val_accuracy: 0.9122\n",
            "Epoch 19/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3576 - accuracy: 0.9140\n",
            "Epoch 19: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 19s 39ms/step - loss: 0.3576 - accuracy: 0.9140 - val_loss: 0.5778 - val_accuracy: 0.8053\n",
            "Epoch 20/20\n",
            "474/476 [============================>.] - ETA: 0s - loss: 0.3732 - accuracy: 0.9105\n",
            "Epoch 20: saving model to model_checkpoints/checkpoint\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.3733 - accuracy: 0.9104 - val_loss: 0.5165 - val_accuracy: 0.8740\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving Model Weigths"
      ],
      "metadata": {
        "id": "3dyGzYL6fVok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"model_checkpoints_complete\" #because we want to save all\n",
        "checkpoint_weights = ModelCheckpoint(\n",
        "    filepath = checkpoint_path,\n",
        "    frecuency = \"epoch\",\n",
        "    save_weights_only = False, #this because we want to save model and wights\n",
        "    monitor = \"val_accuracy\", #to save only the best model\n",
        "    save_best_only = True,\n",
        "    verbose = 1 #show us information during training\n",
        ")"
      ],
      "metadata": {
        "id": "2OV3sGoof0n0"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete = get_model()\n",
        "model_complete.compile(optimizer = \"adam\", loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
        "\n",
        "history_complete = model_complete.fit(\n",
        "    train_generator,\n",
        "    epochs = 20,\n",
        "    callbacks = [checkpoint_weights],\n",
        "    validation_data = validation_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PE3R7c0cf6b0",
        "outputId": "9ac6011e-e09c-4d37-9554-a13a479cd4fd"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.9642 - accuracy: 0.6095\n",
            "Epoch 1: val_accuracy improved from -inf to 0.64885, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 22s 42ms/step - loss: 0.9642 - accuracy: 0.6101 - val_loss: 0.9910 - val_accuracy: 0.6489\n",
            "Epoch 2/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.7173 - accuracy: 0.7528\n",
            "Epoch 2: val_accuracy improved from 0.64885 to 0.66794, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 19s 41ms/step - loss: 0.7173 - accuracy: 0.7528 - val_loss: 0.8816 - val_accuracy: 0.6679\n",
            "Epoch 3/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.6482 - accuracy: 0.7884\n",
            "Epoch 3: val_accuracy improved from 0.66794 to 0.67939, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 18s 38ms/step - loss: 0.6484 - accuracy: 0.7883 - val_loss: 0.7617 - val_accuracy: 0.6794\n",
            "Epoch 4/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.6007 - accuracy: 0.8155\n",
            "Epoch 4: val_accuracy improved from 0.67939 to 0.70992, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 18s 39ms/step - loss: 0.6007 - accuracy: 0.8155 - val_loss: 0.7084 - val_accuracy: 0.7099\n",
            "Epoch 5/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.5634 - accuracy: 0.8302\n",
            "Epoch 5: val_accuracy improved from 0.70992 to 0.73664, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 20s 41ms/step - loss: 0.5635 - accuracy: 0.8300 - val_loss: 0.7037 - val_accuracy: 0.7366\n",
            "Epoch 6/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.5346 - accuracy: 0.8442\n",
            "Epoch 6: val_accuracy did not improve from 0.73664\n",
            "476/476 [==============================] - 17s 37ms/step - loss: 0.5346 - accuracy: 0.8442 - val_loss: 0.6761 - val_accuracy: 0.7214\n",
            "Epoch 7/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.5175 - accuracy: 0.8596\n",
            "Epoch 7: val_accuracy improved from 0.73664 to 0.78244, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 20s 42ms/step - loss: 0.5175 - accuracy: 0.8596 - val_loss: 0.6090 - val_accuracy: 0.7824\n",
            "Epoch 8/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.8668\n",
            "Epoch 8: val_accuracy improved from 0.78244 to 0.82061, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 19s 39ms/step - loss: 0.4766 - accuracy: 0.8671 - val_loss: 0.5754 - val_accuracy: 0.8206\n",
            "Epoch 9/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4737 - accuracy: 0.8716\n",
            "Epoch 9: val_accuracy did not improve from 0.82061\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.4738 - accuracy: 0.8715 - val_loss: 0.5632 - val_accuracy: 0.8206\n",
            "Epoch 10/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.8788\n",
            "Epoch 10: val_accuracy improved from 0.82061 to 0.87023, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 20s 41ms/step - loss: 0.4575 - accuracy: 0.8787 - val_loss: 0.4840 - val_accuracy: 0.8702\n",
            "Epoch 11/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4452 - accuracy: 0.8837\n",
            "Epoch 11: val_accuracy improved from 0.87023 to 0.88931, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 18s 39ms/step - loss: 0.4453 - accuracy: 0.8834 - val_loss: 0.4219 - val_accuracy: 0.8893\n",
            "Epoch 12/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4337 - accuracy: 0.8901\n",
            "Epoch 12: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.4337 - accuracy: 0.8901 - val_loss: 0.4407 - val_accuracy: 0.8855\n",
            "Epoch 13/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.4077 - accuracy: 0.9035\n",
            "Epoch 13: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.4076 - accuracy: 0.9035 - val_loss: 0.5058 - val_accuracy: 0.8626\n",
            "Epoch 14/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.4179 - accuracy: 0.8979\n",
            "Epoch 14: val_accuracy did not improve from 0.88931\n",
            "476/476 [==============================] - 17s 37ms/step - loss: 0.4179 - accuracy: 0.8979 - val_loss: 0.4998 - val_accuracy: 0.8702\n",
            "Epoch 15/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3995 - accuracy: 0.9033\n",
            "Epoch 15: val_accuracy improved from 0.88931 to 0.90458, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 19s 40ms/step - loss: 0.3998 - accuracy: 0.9030 - val_loss: 0.4977 - val_accuracy: 0.9046\n",
            "Epoch 16/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3717 - accuracy: 0.9191\n",
            "Epoch 16: val_accuracy did not improve from 0.90458\n",
            "476/476 [==============================] - 17s 36ms/step - loss: 0.3719 - accuracy: 0.9191 - val_loss: 0.4708 - val_accuracy: 0.8702\n",
            "Epoch 17/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3847 - accuracy: 0.9104\n",
            "Epoch 17: val_accuracy did not improve from 0.90458\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.3845 - accuracy: 0.9102 - val_loss: 0.5139 - val_accuracy: 0.8550\n",
            "Epoch 18/20\n",
            "475/476 [============================>.] - ETA: 0s - loss: 0.3699 - accuracy: 0.9158\n",
            "Epoch 18: val_accuracy did not improve from 0.90458\n",
            "476/476 [==============================] - 19s 40ms/step - loss: 0.3697 - accuracy: 0.9160 - val_loss: 0.4914 - val_accuracy: 0.8779\n",
            "Epoch 19/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3525 - accuracy: 0.9268\n",
            "Epoch 19: val_accuracy improved from 0.90458 to 0.92366, saving model to model_checkpoints_complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r476/476 [==============================] - 19s 40ms/step - loss: 0.3525 - accuracy: 0.9268 - val_loss: 0.4080 - val_accuracy: 0.9237\n",
            "Epoch 20/20\n",
            "476/476 [==============================] - ETA: 0s - loss: 0.3737 - accuracy: 0.9161\n",
            "Epoch 20: val_accuracy did not improve from 0.92366\n",
            "476/476 [==============================] - 18s 37ms/step - loss: 0.3737 - accuracy: 0.9161 - val_loss: 0.3852 - val_accuracy: 0.9160\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving in a ZIP"
      ],
      "metadata": {
        "id": "OOvx1Esdf9p0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip model_checkpoints_complete *"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07k3X_epf_4u",
        "outputId": "12701e77-5240-4438-ae60-1d7a3b305aaf"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/ (stored 0%)\n",
            "  adding: drive/ (stored 0%)\n",
            "  adding: model_checkpoints/ (stored 0%)\n",
            "  adding: model_checkpoints_complete/ (stored 0%)\n",
            "  adding: models/ (stored 0%)\n",
            "  adding: sample_data/ (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving in H5py"
      ],
      "metadata": {
        "id": "TsMRa4Z2gRvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyyaml h5py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQpEzXk7gBxs",
        "outputId": "b43c4260-b1a4-4c0f-dd02-2a8fcfa4718b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (6.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.10/dist-packages (from h5py) (1.22.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete.save(\"save_model_complete/mymodel\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W7EyHfCo4Ovv",
        "outputId": "72fcc74b-47af-4981-cf79-dd5880e23b7a"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew = tf.keras.models.load_model(\"save_model_complete/mymodel\")"
      ],
      "metadata": {
        "id": "KUAOCa_R4Qa0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftDQPwe24SsC",
        "outputId": "57fcc606-7638-47fe-c929-c06f03ab16a4"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 6s 51ms/step - loss: 0.3940 - accuracy: 0.9077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3940390944480896, 0.9077040553092957]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_complete.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTnjMWpG4UoL",
        "outputId": "4918f6cf-f48a-4c69-afbb-0fb00617d880"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 5s 49ms/step - loss: 0.3940 - accuracy: 0.9077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3940391540527344, 0.9077040553092957]"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew.save(\"brain_model.h5\")"
      ],
      "metadata": {
        "id": "wiqYn7p_5xeU"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew2 = tf.keras.models.load_model(\"brain_model.h5\")"
      ],
      "metadata": {
        "id": "8w_JgIEfgamx"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_completenew2.evaluate(test_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xyGjhRfJgd6k",
        "outputId": "ef84993a-a1eb-4252-f011-845272599b49"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 5s 43ms/step - loss: 0.3940 - accuracy: 0.9077\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3940390646457672, 0.9077040553092957]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving the model to use tendorflowJS"
      ],
      "metadata": {
        "id": "6Ls9yq2JmINr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflowjs"
      ],
      "metadata": {
        "id": "stH4xgtrmGSy",
        "outputId": "78c3fca3-bf99-4080-c982-d2c91f8eff94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflowjs\n",
            "  Downloading tensorflowjs-4.9.0-py3-none-any.whl (89 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/89.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting flax<0.6.3,>=0.6.2 (from tensorflowjs)\n",
            "  Downloading flax-0.6.2-py3-none-any.whl (189 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.9/189.9 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib_resources>=5.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (6.0.0)\n",
            "Requirement already satisfied: jax>=0.3.16 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.4.13)\n",
            "Requirement already satisfied: tensorflow<3,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (2.12.0)\n",
            "Collecting tensorflow-decision-forests>=1.3.0 (from tensorflowjs)\n",
            "  Downloading tensorflow_decision_forests-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (1.16.0)\n",
            "Requirement already satisfied: tensorflow-hub>=0.13.0 in /usr/local/lib/python3.10/dist-packages (from tensorflowjs) (0.14.0)\n",
            "Collecting packaging~=20.9 (from tensorflowjs)\n",
            "  Downloading packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.9/40.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.12 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.22.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (3.7.1)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (1.0.5)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.5)\n",
            "Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.40)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (13.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (4.7.1)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from flax<0.6.3,>=0.6.2->tensorflowjs) (6.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.16->tensorflowjs) (1.10.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from packaging~=20.9->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.8.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (16.0.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (67.7.2)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<3,>=2.12.0->tensorflowjs) (0.32.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (1.5.3)\n",
            "Collecting tensorflow<3,>=2.12.0 (from tensorflowjs)\n",
            "  Downloading tensorflow-2.13.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (524.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m524.1/524.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from tensorflow-decision-forests>=1.3.0->tensorflowjs) (0.40.0)\n",
            "Collecting wurlitzer (from tensorflow-decision-forests>=1.3.0->tensorflowjs)\n",
            "  Downloading wurlitzer-3.0.3-py3-none-any.whl (7.3 kB)\n",
            "Collecting keras<2.14,>=2.13.1 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.14,>=2.13 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow<3,>=2.12.0->tensorflowjs)\n",
            "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.8/440.8 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions>=4.1.1 (from flax<0.6.3,>=0.6.2->tensorflowjs)\n",
            "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (2.14.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.3.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (8.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->flax<0.6.3,>=0.6.2->tensorflowjs) (2.8.2)\n",
            "Requirement already satisfied: chex>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.7)\n",
            "Requirement already satisfied: jaxlib>=0.1.37 in /usr/local/lib/python3.10/dist-packages (from optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.4.13+cuda11.cudnn86)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->tensorflow-decision-forests>=1.3.0->tensorflowjs) (2022.7.1)\n",
            "Requirement already satisfied: dm-tree>=0.1.5 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.8)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.5->optax->flax<0.6.3,>=0.6.2->tensorflowjs) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax<0.6.3,>=0.6.2->tensorflowjs) (0.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow<3,>=2.12.0->tensorflowjs) (3.2.2)\n",
            "Installing collected packages: wurlitzer, typing-extensions, tensorflow-estimator, packaging, keras, tensorboard, tensorflow, flax, tensorflow-decision-forests, tensorflowjs\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.7.1\n",
            "    Uninstalling typing_extensions-4.7.1:\n",
            "      Successfully uninstalled typing_extensions-4.7.1\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.12.0\n",
            "    Uninstalling tensorflow-estimator-2.12.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.12.0\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 23.1\n",
            "    Uninstalling packaging-23.1:\n",
            "      Successfully uninstalled packaging-23.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.12.0\n",
            "    Uninstalling keras-2.12.0:\n",
            "      Successfully uninstalled keras-2.12.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.12.3\n",
            "    Uninstalling tensorboard-2.12.3:\n",
            "      Successfully uninstalled tensorboard-2.12.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.12.0\n",
            "    Uninstalling tensorflow-2.12.0:\n",
            "      Successfully uninstalled tensorflow-2.12.0\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.7.0\n",
            "    Uninstalling flax-0.7.0:\n",
            "      Successfully uninstalled flax-0.7.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "statsmodels 0.13.5 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\n",
            "xarray 2022.12.0 requires packaging>=21.3, but you have packaging 20.9 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed flax-0.6.2 keras-2.13.1 packaging-20.9 tensorboard-2.13.0 tensorflow-2.13.0 tensorflow-decision-forests-1.5.0 tensorflow-estimator-2.13.0 tensorflowjs-4.9.0 typing-extensions-4.5.0 wurlitzer-3.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "keras",
                  "packaging",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorrt"
      ],
      "metadata": {
        "id": "hzS1TWzBpK7m",
        "outputId": "ecdc7d53-f955-4689-b1fc-e3a2a4389ca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorrt\n",
            "  Downloading tensorrt-8.6.1.tar.gz (16 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: tensorrt\n",
            "  Building wheel for tensorrt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tensorrt: filename=tensorrt-8.6.1-py2.py3-none-any.whl size=16973 sha256=f160077a87864ba98cb526a63ca7596fdadf0cde93928999ba59b22aa33632fa\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/29/56/abdffd4c604f255b5254bef3f1c598ab7811ea020540599438\n",
            "Successfully built tensorrt\n",
            "Installing collected packages: tensorrt\n",
            "Successfully installed tensorrt-8.6.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir output_folder"
      ],
      "metadata": {
        "id": "oLZh5B1QmWfk"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tensorflowjs_converter --input_format keras brain_model.h5 output_folder"
      ],
      "metadata": {
        "id": "uR8MStXembp4",
        "outputId": "a97192b1-907c-40a1-de26-e407b8981329",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-31 06:33:36.054920: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    }
  ]
}